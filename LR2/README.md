# Лабораторная работа 2

### Задание
Сформировать отчёт с информацией о 10 наиболее популярных языках программирования по итогам года за период с 2010 по 2020 годы. Отчёт будет отражать динамику изменения популярности языков программирования и представлять собой набор таблиц "топ-10" для каждого года.
Получившийся отчёт сохранить в формате Apache Parquet.
Для выполнения задания вы можете использовать любую комбинацию Spark API: RDD API, Dataset API, SQL API

### Решение

Лабораторная работа была реализована на языке Python с использованием сервера mapr.
![image](https://github.com/VadimKolodin/bigData/assets/105828231/e7356fc9-4485-405e-ae44-314775fdcde6)
![image](https://github.com/VadimKolodin/bigData/assets/105828231/86ec9c27-97f6-4cfa-b4b5-9f86b592a4c4)
На рисунках выше показана реализация чтения исходных данных, а именно, чтение файлов с расширениями csv и xml. Для этого был использован метод read для формата csv и xml соответственно, также продемонстрированы примеры из этих файлов (первые 10 записей в файле с языками программирования, без учета 0 строки-заголовка, первый пост из файла posts_sample.xml)
![image](https://github.com/VadimKolodin/bigData/assets/105828231/78cb4e09-c7f5-4c0b-bf09-0100d2725bd3)
![image](https://github.com/VadimKolodin/bigData/assets/105828231/4daad4b5-30b7-48ed-835f-5ff508b1ff82)
Рисунки выше содержат реализацию основного задания – составления отчета о топ-10 языках программирования за каждый год.
Описание реализации: из выборки постов получаются года публикации, чтобы получить диапазон значений лет, за которые можно сформировать отчет; далее для каждого года из изначальной выборки фильтруются те строки, где можно получить тэг, содержащий язык; после чего все строки подвергаются преобразованию в объекты с помощью функции initPost и убираются строки, где год публикации не соответствует отчетному; далее получаются пары значений из идентификатора языка и кол-ва просмотров поста; после чего применяется функция редукции по кол-ву просмотров постов для каждого языка. Далее записи сортируются по кол-ву просмотров и преобразовываются в Dataframe. Из получившихся данных выбираются колонки, соответствующие названию языка (с помощью ранее составленного списка языков) и кол-ва просмотров, берутся первые 10 значений. Итоговые данные складывается в словарь. Наконец, содержимое словаря выводится и сохраняется в файлы формата parquet:
![image](https://github.com/VadimKolodin/bigData/assets/105828231/83fa8fe5-ffef-4ca2-8835-820cc7547719) ![image](https://github.com/VadimKolodin/bigData/assets/105828231/1530f9eb-3cac-4be6-a2ff-542c8eaf7efa)



